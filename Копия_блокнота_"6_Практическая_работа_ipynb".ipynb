{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4Xl9TmXcY-sX"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/repatoon/sergin/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%226_%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['dekd', 'fsrf', 'frsfsre']\n",
        "numbers = [1, 4, 676, 89]"
      ],
      "metadata": {
        "id": "UFmRyMOU_IPx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in words:\n",
        "  print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PnR7I_c_cLp",
        "outputId": "7a01bd4b-911e-4b00-bb72-9f4bf4d0727b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dekd\n",
            "fsrf\n",
            "frsfsre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_list = []\n",
        "\n",
        "for n in range(13):\n",
        "  example_list.append(n)"
      ],
      "metadata": {
        "id": "UAC0SiiQ_fDh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"text\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.is_stop)\n",
        ""
      ],
      "metadata": {
        "id": "xdogESxA_vMw",
        "outputId": "0025ed42-cec0-41b7-e0fd-00b1e4ad0c0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируйте библиотеку spacy. Загрузите анализатор для английского языка."
      ],
      "metadata": {
        "id": "QTeQrfm4uU3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"text\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token.is_stop)"
      ],
      "metadata": {
        "id": "4-PrZvCXmSRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b23330-1659-46b6-a770-4f74c36c9fb7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 1.** Напишите функцию, которая принимает текст в формате строки в качестве аргумента и возвращает список токенов.\n",
        "\n"
      ],
      "metadata": {
        "id": "wuQRsR1iWz5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def texttoken(text):\n",
        "  doc = nlp(text)\n",
        "  return [token.text for token in doc]\n",
        "\n",
        "inputtext = input(\"Введите текст: \")\n",
        "tokens = texttoken(inputtext)\n",
        "print(\"\\nСписок: \")\n",
        "print(f\"{tokens}\")"
      ],
      "metadata": {
        "id": "McEW8vlym6C5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a86c11-3032-484e-c6b3-0771b684d825"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите текст: Напишите функцию, которая принимает текст в формате строки в качестве аргумента и возвращает список токенов\n",
            "\n",
            "Список: \n",
            "['Напишите', 'функцию', ',', 'которая', 'принимает', 'текст', 'в', 'формате', 'строки', 'в', 'качестве', 'аргумента', 'и', 'возвращает', 'список', 'токенов']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 2.** Напишите функцию, которая принимает **список токенов** в качестве аргумента и возвращает **список лемм** для каждого токена в тексте."
      ],
      "metadata": {
        "id": "Uy9x4h8mUf7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def lemmiget(text):\n",
        "  doc = nlp(text)\n",
        "  return [token.lemma_ for token in doc if not token.is_punct]\n",
        "\n",
        "user_text = input(\"Введите текст для лемматизации: \")\n",
        "lemmi = lemmiget(user_text)\n",
        "print(\"Леммы:\", lemmi)"
      ],
      "metadata": {
        "id": "sFm-GzuHUfbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2544204-825c-4c42-b0be-3ae88e3109d7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите текст для лемматизации: He still had time. \"Allow me,\" he said, and hurried between the two policemen through into his room. \"He seems sensible enough,\" he heard them say behind him.\n",
            "Леммы: ['he', 'still', 'have', 'time', 'allow', 'I', 'he', 'say', 'and', 'hurry', 'between', 'the', 'two', 'policeman', 'through', 'into', 'his', 'room', 'he', 'seem', 'sensible', 'enough', 'he', 'hear', 'they', 'say', 'behind', 'he']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 3.** Напишите функцию, которая принимает слово (токен) в качестве аргумента и возвращает его **часть речи**."
      ],
      "metadata": {
        "id": "e1scII2mYG88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def part_of_speech(word):\n",
        "  doc = nlp(word)\n",
        "  return doc[0].pos_\n",
        "\n",
        "\n",
        "user_word = input(\"Введите слово: \")\n",
        "print(f\"Часть речи: {part_of_speech(user_word)}\")"
      ],
      "metadata": {
        "id": "xPTppZdvaiBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85bd4d4-0490-4051-e2c2-db0b78f94600"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите слово: lock\n",
            "Часть речи: VERB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 4.** Напишите функцию, которая принимает **список токенов** в качестве аргумента и возвращает отфильтрованный список токенов, из которого удалены стоп-слова. При решении используйте библиотеку spacy.\n",
        "\n",
        "**Задача 4.1.** Добавьте в функцию параметр `additional_filter`, который будет содержать список слов, которые также нужно исключить из исходного списка токенов (если список пустой, то дополнительно ничего исключаться не будет).\n",
        "\n",
        "**Задача 4.2.** Добавьте в функцию параметр  `filter_numbers` булевого типа данных, который:\n",
        "\n",
        "\n",
        "*   при значении True отфильтрует список токенов таким образом, чтобы из него также были удалены такие токены, в которых есть хотя бы одна цифра;\n",
        "*   при значении False не будет дополнительно фильтровать токены по критерию наличия цифры.\n",
        "\n",
        "**Задача 4.3.** Добавьте в функцию параметр `filter_named_entities` булевого типа данных, который:\n",
        "\n",
        "*   при значении True отфильтрует список токенов таким образом, чтобы из него также были удалены именованные сущности;\n",
        "*   при значении False не будет дополнительно фильтровать токены.\n",
        "\n",
        "При решении задачи учтите, что библиотека spacy может разбивать текст на токены по-разному при обычном разбиении и при выявлении именованных сущностей (например, именованной сущностью может являться словосочетание \"earier this week\").\n",
        "\n",
        "\n",
        "Перед решением задачи может быть полезно ознакомиться с такими методами работы со строками, как find(), replace() и др."
      ],
      "metadata": {
        "id": "Ew5ZkttGWjK3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YvU98p_YGbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 5.** Протестируйте работу функций из задач 1-4 (напишите вызовы каждой функции) на примере произвольного текста на английском языке."
      ],
      "metadata": {
        "id": "SAm5PWr0o8Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "10KfPNcZo71K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задача 6*.** Изучите [статью об автоматическом определении тем в наборе текстов](https://medium.com/data-science/let-us-extract-some-topics-from-text-data-part-i-latent-dirichlet-allocation-lda-e335ee3e5fa4).\n",
        "\n",
        "Напишите программу, которая выявит в наборе текстов N тем (количество тем определите самостоятельно экспериментальным образом). Оцените качество разбиения с помощью метрики `coherence score`.\n",
        "\n",
        "На этапе пре-процессинга можно использовать функции, написанные при решении задач 1-4 или попробовать сделать это с помощью библиотеки NLTK, чтобы изучить альтернативные способы решения задачи.\n",
        "\n",
        "Можно запустить код ниже, чтобы загрузить набор текстов в переменную texts (тип данных – список) и работать с ним. Данный набор текстов представляет собой реальные данные о поисковых запросах в Яндекс.Поиске за определенный период.\n",
        "\n",
        "Либо можно использовать свой набор текстов."
      ],
      "metadata": {
        "id": "_gOGnii0sX7y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2h9WuojHrnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNkrkuG9upaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}